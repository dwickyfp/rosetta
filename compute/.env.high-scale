# Rosetta Compute Engine - High Scale Configuration
# Optimized for 20+ pipelines with 100+ tables each
# Copy to .env and adjust values based on your environment

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
CONFIG_DATABASE_URL=postgresql://postgres:postgres@localhost:5433/rosetta

# Database host configuration
ROSETTA_DB_HOST=localhost
ROSETTA_DB_PORT=5433
ROSETTA_DB_NAME=rosetta
ROSETTA_DB_USER=postgres
ROSETTA_DB_PASSWORD=postgres

# NOTE: Ensure PostgreSQL max_connections >= 200
# Run: ALTER SYSTEM SET max_connections = 200; SELECT pg_reload_conf();

# ============================================================================
# DEBEZIUM ENGINE TUNING
# ============================================================================

# Batch Size: Number of records processed per batch
# Higher = better throughput, more memory
# Recommended for high-scale: 4096-8192
PIPELINE_MAX_BATCH_SIZE=4096

# Queue Size: Internal buffer between Debezium and event handler
# Should be 2-4x batch size
PIPELINE_MAX_QUEUE_SIZE=16384

# Poll Interval: How often Debezium checks for new events (milliseconds)
# Higher = lower CPU, slightly higher latency
PIPELINE_POLL_INTERVAL_MS=1000

# Offset flush interval (milliseconds)
# How often to persist offset to disk
DEBEZIUM_OFFSET_FLUSH_INTERVAL_MS=60000

# Offset storage path
DEBEZIUM_OFFSET_STORAGE_PATH=./tmp/offsets

# ============================================================================
# PIPELINE MANAGER TUNING
# ============================================================================

# How often to check database for pipeline status changes (seconds)
# Higher = lower DB load, slower response to START/PAUSE
PIPELINE_CHECK_INTERVAL=10

# ============================================================================
# CONNECTION POOL OPTIMIZATION
# ============================================================================

# WARNING: These are not currently configurable via env vars
# You must edit the code directly:
#
# In compute/main.py line 108:
#   init_connection_pool(min_conn=2, max_conn=8)
#
# In compute/core/manager.py line 67:
#   init_connection_pool(min_conn=1, max_conn=3)
#
# This limits total connections to ~68 (8 main + 20*3 pipelines)

# ============================================================================
# DEAD LETTER QUEUE (DLQ) CONFIGURATION
# ============================================================================

# Redis connection (used for DLQ storage)
REDIS_URL=redis://localhost:6379/0

# DLQ key prefix
DLQ_KEY_PREFIX=rosetta:dlq

# Maximum messages per stream (prevents unbounded growth)
DLQ_MAX_STREAM_LENGTH=100000

# Consumer group name
DLQ_CONSUMER_GROUP=dlq_recovery

# Recovery check interval (seconds)
# How often to attempt replaying failed messages
DLQ_CHECK_INTERVAL=30

# Batch size for DLQ recovery
DLQ_BATCH_SIZE=100

# Max retries before giving up
DLQ_MAX_RETRY_COUNT=10

# Max age before purging (days)
DLQ_MAX_AGE_DAYS=7

# XREADGROUP block timeout (milliseconds)
DLQ_BLOCK_MS=2000

# ============================================================================
# API SERVER
# ============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8001

# ============================================================================
# LOGGING
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Enable debug mode (overrides LOG_LEVEL)
DEBUG=false

# Log format
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ============================================================================
# HORIZONTAL SCALING (Optional)
# ============================================================================

# Uncomment to distribute pipelines across multiple compute instances
# COMPUTE_INSTANCE_ID=1
# TOTAL_COMPUTE_INSTANCES=2

# How it works:
# - Instance 1 handles pipelines where pipeline_id % 2 == 0
# - Instance 2 handles pipelines where pipeline_id % 2 == 1

# ============================================================================
# MONITORING & METRICS
# ============================================================================

# WAL monitoring interval (seconds)
# Backend API monitors WAL size and updates pipeline_metadata
WAL_MONITOR_INTERVAL_SECONDS=30

# ============================================================================
# RESOURCE LIMITS (System Level)
# ============================================================================

# These should be set at the operating system level

# Recommended ulimit settings:
# ulimit -n 4096          # Open file descriptors
# ulimit -u 4096          # Max user processes
# ulimit -v unlimited     # Virtual memory

# Recommended Docker resource limits (if containerized):
# --memory=24g            # 24GB RAM
# --cpus=8                # 8 CPU cores
# --pids-limit=200        # Prevent fork bomb

# ============================================================================
# PERFORMANCE MONITORING QUERIES
# ============================================================================

# Use these queries to monitor system health

# 1. Active pipeline count:
# SELECT COUNT(*) FROM pipelines WHERE status = 'START';

# 2. Database connections:
# SELECT count(*), application_name 
# FROM pg_stat_activity 
# WHERE application_name LIKE 'rosetta%'
# GROUP BY application_name;

# 3. Replication slot lag (on source databases):
# SELECT 
#   slot_name,
#   active,
#   pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) AS lag
# FROM pg_replication_slots 
# WHERE slot_name LIKE 'rosetta_%'
# ORDER BY lag DESC;

# 4. DLQ depth (Redis):
# redis-cli --scan --pattern "rosetta:dlq:*" | \
#   xargs -I {} sh -c 'echo -n "{}: "; redis-cli XLEN {}'

# 5. Pipeline metadata health:
# SELECT 
#   id, 
#   health_status, 
#   last_heartbeat_at,
#   pg_size_pretty(wal_size) AS wal_size
# FROM pipeline_metadata
# WHERE health_status != 'HEALTHY'
# ORDER BY last_heartbeat_at DESC;
